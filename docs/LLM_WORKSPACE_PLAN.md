# LLM Codex Pipeline Plan (Nuxt + Python)

This document describes a **reusable, staged pipeline** for long-form sources (e.g. 30â€‘minute YouTube cooking videos) that turns transcripts into SEOâ€‘ready MDX blogs with sectionâ€‘level editing.

It is the source of truth for the Nuxt implementation and is grounded in what already exists in the current Python backend.

---

## 1. Goals

- **Codexâ€‘style flow** for long videos:
  - Transcribing â†’ reading â†’ planning â†’ writing sections â†’ assembling â†’ SEO â†’ ready to publish.
- **Sectionâ€‘first architecture**:
  - Outline + sections are firstâ€‘class, not an afterthought.
- **Reusability**:
  - Same pipeline works for any long `source_content` (YouTube today, Docs later).
- **Orgâ€‘scoped, Nuxtâ€‘native**:
  - Reuse existing `organization` / betterâ€‘auth patterns and Drizzle ORM.

We intentionally avoid job/queue plumbing and extra SEO UI in v1; those can be layered on later.

---

## 2. Core Data Model (Summary)

We keep the existing entities from the prior plan but focus on how they support the pipeline.

- **`source_content`**
  - Where material comes from.
  - Fields (conceptual):
    - `id`, `organization_id`, `created_by_user_id`.
    - `source_type` (`"youtube" | "raw_text" | "google_doc" | ...`).
    - `external_id` (e.g. YouTube video ID).
    - `title`.
    - `source_text` (full transcript / body the LLM reads).
    - `metadata` JSON (providerâ€‘specific).
    - `ingest_status` (`pending | ingested | failed`).

- **`chunk`** (required v1)
  - Transcript segments used for RAG.
  - Perâ€‘chunk: `id`, `organization_id`, `source_content_id`, `chunk_index`, `start_char`, `end_char`, `text_preview`, timestamps, etc.
  - Embeddings stored in vector store keyed by `organization_id + source_content_id + chunk_index`.

- **`content`**
  - The logical article/post.
  - Fields: `id`, `organization_id`, `source_content_id`, `slug`, `title`, `status`, `content_type`, `primary_keyword`, `target_locale`, `current_version_id`, timestamps.

  - **`content_version`**
  - Immutable snapshot of a draft or edit.
  - Fields: `id`, `content_id`, `version`, `created_by_user_id`, timestamps.
    - `version: number` â€” monotonically incrementing integer starting at 1 (e.g. 1, 2, 3â€¦).
  - Content fields:
    - `frontmatter` JSON (SEO+metadata).
    - `body_mdx` (full MDX).
    - `body_html` (rendered for preview/publish).
    - `sections` JSON (see section 4).
    - `assets` JSON (including `{ generator: { source, model } }`).
    - `seo_snapshot` JSON (optional v1).

- **`publication`**
  - Links `content_version` â†’ external systems via `integration`.
  - Used later for WordPress / Docs publishing.

All new tables are **orgâ€‘scoped** and follow existing Nuxt SaaS conventions.

---

## 3. Endâ€‘toâ€‘End Pipeline Stages

For a YouTube video, the **target** pipeline is:

1. **Ingest + transcript + chunks**
2. **Plan / outline (content plan)**
3. **Frontmatter generation**
4. **Section generation (perâ€‘section writing, RAGâ€‘aware)**
5. **Assemble full version from sections**
6. **SEO analysis**
7. **Section patching (chatâ€‘driven editing)**

Each stage has a conceptual API and a brief note on **what exists today vs what to build**.

### 3.0 Current implementation (COMPLETED âœ…)

~~Today, `POST /api/content/generate` calls `generateContentDraft`, which:~~

**REBUILT**: `generateContentDraft` has been transformed into a **staged pipeline** (`server/services/content/generation.ts`):

1. **Chunking/Fetching Stage** (lines 62-215):
   - Resolves `inputText` from either `text` or `sourceContent.sourceText`
   - Fetches and chunks transcript data for RAG context
   - Prepares source material for AI planning

2. **AI-Planned Brief Stage** (lines 300-406):
   - LLM generates structured outline and frontmatter
   - Derives SEO metadata and content plan
   - Creates stable foundation before section generation

3. **RAG-Contextualized Section Generation** (lines 409-640):
   - Per-section content generation with transcript chunk context
   - JSON parsing safeguards for reliable structured output
   - Individual section writing with RAG-aware prompts

4. **MDX Assembly Stage**:
   - Stitches sections into complete MDX document
   - Captures section offsets, metadata, and assets
   - Persists new `content_version` with structured sections

**UI Integration COMPLETED**:
- Chat landing page (`app/pages/[slug]/chat.vue`) displays real draft data in cards
- Content detail route (`app/pages/[slug]/content/[id].vue`) renders staged pipeline data
- Section-level display with summaries, metadata, and editing capabilities

This provides `/api/content/generate` and `/api/chat` with **deterministic plan â†’ sections â†’ assemble behavior** while maintaining backward compatibility.

---

## 3.1 Ingest + Transcript + Chunks âœ… COMPLETED

**Implemented endpoint**

- `POST /api/source-content/youtube` (`server/api/source-content/youtube.post.ts`)

- **Request**
  - `youtubeUrl: string`
  - `titleHint?: string`

- **Response**
  - `sourceContentId: string`
  - `status: "transcribing" | "ready"`
  - `metadata: { videoId, durationSeconds?, channel?, thumbnailUrl? }`

**Implemented Behaviour** âœ…

- Parse YouTube URL â†’ video ID âœ…
- Upsert `source_content` for the org âœ…
- Fetch transcript â†’ normalize to `source_text` âœ…
- Update `ingest_status = 'ingested'` âœ…
- Chunk `source_text` into overlapping segments and write `chunk` rows âœ…
- Compute embeddings and index them in vector store âœ…

**Implementation Details**

- **Database Schema**: `chunk` table created (`server/database/schema/chunk.ts`) âœ…
- **Chunking Service**: `chunkSourceContent` helper (`server/services/sourceContent/chunkSourceContent.ts`) âœ…
- **YouTube Ingest**: Modified `ingestYouTubeSource` to invoke chunking after transcript storage âœ…
- **Authentication**: Google OAuth integration for YouTube captions API âœ…

**Testing Results** âœ…
- Successfully ingests YouTube videos with transcript chunking
- Creates searchable chunk rows in database
- Integrates with existing RAG pipeline for content generation

---

## 3.2 Plan / Outline (Content Plan) âœ… INTEGRATED

**Implementation Status**

- **Integrated into staged pipeline** (`server/services/content/generation.ts` lines 300-406) âœ…
- Planning occurs as **AI-Planned Brief Stage** within `generateContentDraft` âœ…

**Implemented Behaviour** âœ…

- LLM reads:
  - Chunked transcript data with RAG context âœ…
  - Content generation instructions and target schema âœ…
  - Org-scoped content preferences âœ…
- Produces structured outline + frontmatter before section generation âœ…
- Creates stable foundation for per-section writing âœ…

**Integration Details**

- **Not exposed as separate endpoint** - integrated into content generation pipeline
- **Frontmatter derivation**: Title, description, SEO metadata generated from AI brief âœ…
- **Section planning**: Structured outline feeds into per-section generation âœ…
- **JSON parsing safeguards**: Reliable structured output handling âœ…

**Testing Results** âœ…
- Successfully generates structured content plans from YouTube transcripts
- Produces consistent frontmatter and section outlines
- Feeds into downstream section generation with proper context

---

## 3.3 Frontmatter Generation âœ… INTEGRATED

**Implementation Status**

- **Integrated into AI-Planned Brief Stage** (`server/services/content/generation.ts`) âœ…
- Frontmatter generated as part of structured planning phase âœ…

**Implemented Behaviour** âœ…

- Takes outline + SEO hints from AI planning stage âœ…
- Applies content-type specific metadata (blog_post, how_to, etc.) âœ…
- Emits stable `frontmatter` object persisted on `content_version` âœ…
- Includes: title, description, slug, content_type, schema hints âœ…

**Integration Details**

- **Not separate endpoint** - part of unified generation pipeline
- **Stable before section writing**: Frontmatter locked in during planning phase âœ…
- **Org-scoped**: Respects organization context and branding âœ…
- **SEO-aware**: Incorporates keyword targeting and schema markup âœ…

**Testing Results** âœ…
- Generates consistent frontmatter metadata from transcript content
- Properly structures SEO-friendly titles and descriptions
- Maintains stability across section generation phases
- Displays correctly in content detail UI with metadata cards

---

## 3.4 Section Generation (Perâ€‘Section, RAGâ€‘Aware) âœ… COMPLETED

**Implementation Status**

- **RAG-Contextualized Section Generation** (`server/services/content/generation.ts` lines 409-640) âœ…
- Per-section writing with transcript chunk context âœ…

**Implemented Behaviour** âœ…

For each planned section:

- Build retrieval query based on section title/type/notes âœ…
- Query chunk embeddings for most relevant transcript `chunk` previews (RAG) âœ…
- LLM call for **only that section** with:
  - System: "You are writing ONE section of a blog postâ€¦" âœ…
  - User: section description + RAG snippets + global instructions âœ…
- Produce `body_mdx` for that section âœ…
- JSON parsing safeguards for reliable structured output âœ…

**Implementation Details**

- **RAG Integration**: Uses existing chunk embeddings and retrieval system âœ…
- **Section-Specific Prompts**: Tailored prompts for each section type and context âœ…
- **Error Handling**: JSON parsing safeguards prevent generation failures âœ…
- **Context Assembly**: Similar to existing `_gather_transcript_context` patterns âœ…

**Testing Results** âœ…
- Successfully generates individual sections with relevant transcript context
- Produces structured sections with proper MDX formatting
- Integrates seamlessly with chunk-based RAG system
- Displays sections with summaries and expandable full text in UI

---

## 3.5 Assemble Full Version From Sections âœ… COMPLETED

**Implementation Status**

- **MDX Assembly Stage** integrated into `generateContentDraft` pipeline âœ…
- Stitches sections into complete MDX document âœ…

**Implemented Behaviour** âœ…

- Build `body_mdx` from structured sections:
  - `# {frontmatter.title}` âœ…
  - For each section in order: `## {s.title}\n\n{s.body_mdx}\n` âœ…
  - Proper heading hierarchy (H2, H3, etc.) âœ…
- Capture section offsets, metadata, and assets âœ…
- Persist new `content_version` row and update `content.current_version_id` âœ…
- Generate assets metadata with generator info âœ…

**Implementation Details**

- **Section Offset Tracking**: Captures `startOffset` and `endOffset` for each section âœ…
- **Metadata Preservation**: Maintains section-level metadata and word counts âœ…
- **Asset Management**: Records generator source, model, and creation metadata âœ…
- **Version Management**: Creates new `content_version` with complete structured data âœ…

**Testing Results** âœ…
- Successfully assembles complete MDX documents from individual sections
- Maintains proper section structure and metadata
- Creates versioned content with full traceability
- Displays assembled content correctly in content detail UI with full MDX body

---

## 3.6 SEO Analysis âš ï¸ PARTIAL

**Implementation Status**

- **Basic SEO metadata generation** integrated into content pipeline âœ…
- **Full SEO analysis endpoint** not yet implemented âŒ

**Current Implementation** âœ…

- Frontmatter includes SEO-friendly metadata (title, description, schema hints) âœ…
- Word count and section structure tracking âœ…
- Content type and schema awareness âœ…
- Basic metadata quality from AI planning stage âœ…

**Missing Implementation** âŒ

- Dedicated SEO analysis endpoint
- Comprehensive readability scoring
- Keyword focus analysis
- Schema validation
- SEO suggestions and recommendations
- `seo_snapshot` storage on content versions

**Next Steps**

- Port existing SEO analyzer logic to Nuxt
- Create dedicated `/api/content/{contentId}/versions/{versionId}/seo` endpoint
- Integrate SEO analysis into content generation pipeline
- Store SEO snapshots on `content_version` records

---

## 3.7 Section Patching (Chatâ€‘Driven Edits) âš ï¸ FOUNDATION READY

**Implementation Status**

- **Foundation components implemented** âœ…
- **Dedicated section patching endpoint** not yet implemented âŒ

**Available Building Blocks** âœ…

- RAG system with chunk embeddings and retrieval âœ…
- Section-aware content structure in `content_version.sections` âœ…
- AI Gateway integration for section-specific prompts âœ…
- Content versioning and assembly pipeline âœ…
- Organization-scoped access controls âœ…

**UI Foundation** âœ…

- Content detail page displays individual sections with summaries âœ…
- Section expansion interface ("Show full section") âœ…
- Editing chat module present in content detail view âœ…
- Section-level metadata and structure preserved âœ…

**Missing Implementation** âŒ

- Dedicated `/api/content/{contentId}/sections/{sectionId}/patch` endpoint
- Section-specific editing prompts and context assembly
- RAG-aware section rewriting logic
- Automatic reassembly and new version creation after section edits

**Next Steps**

- Implement section patching endpoint using existing RAG and versioning infrastructure
- Create section-specific editing prompts similar to existing patterns
- Wire section editing to chat interface for in-context editing experience

---

## 4. Sections JSON Shape (On `content_version.sections`)

Sections are the structured index over `body_mdx` used for:

- Rendering a TOC.
- Sectionâ€‘level generation and patching.
- SEO and schemaâ€‘aware enrichment.

**Canonical shape** (conceptual):

- Each section object:
  - `section_id: string` â€” stable id (UUID or deterministic).
  - `index: number` â€” 0â€‘based order.
  - `type: string` â€” e.g. `"intro" | "body" | "faq" | "cta" | "recipe_step"`.
  - `level?: number` â€” heading level (2 for H2, 3 for H3), if applicable.
  - `title?: string` â€” heading text.
  - `anchor?: string` â€” slug/anchor for deep links.
  - `startOffset?: number` â€” optional char index into `body_mdx`.
  - `endOffset?: number` â€” optional char index into `body_mdx`.
  - `wordCount: number` â€” perâ€‘section word count.
  - `summary?: string` â€” optional summary.
  - `body_mdx?: string` â€” body for this section (used heavily in patch flow).
  - `meta?: Record<string, any>` â€” arbitrary hints (importance, SEO flags, todos, etc.).

**Notes**

- Existing section extraction utilities already work with a very similar shape; Nuxt should align field names where practical (e.g. `section_id`, `index`, `title`, `body_mdx`, `summary`).

---

## 5. Chatâ€‘First UX and Pipeline Triggers âœ… COMPLETED

**Implementation Status**

- **Chat-driven content generation** fully implemented âœ…
- **Pipeline integration** with natural conversation flow âœ…

**Implemented Behaviour** âœ…

- **`POST /api/chat`** with URL detection and content generation âœ…
  - Detect YouTube URLs in chat messages âœ…
  - Upsert `source_content` for YouTube videos âœ…
  - Trigger complete pipeline stages:
    1. Ingest + chunks (via YouTube ingest API) âœ…
    2. Plan (AI-planned brief stage) âœ…
    3. Frontmatter (integrated into planning) âœ…
    4. Generate sections (RAG-aware per-section writing) âœ…
    5. Assemble version (MDX assembly with metadata) âœ…
    6. ~~Run SEO analysis~~ (basic SEO metadata only) âš ï¸
  - Return final `contentId`/`versionId` âœ…

**UI Implementation** âœ…

- **Chat Landing Page** (`app/pages/[slug]/chat.vue`):
  - Real draft data displayed in cards âœ…
  - Status, content type, section/word counts âœ…
  - Quick navigation and actions per draft âœ…
  - "New Draft vs existing drafts" dropdown âœ…

- **Content Detail Route** (`app/pages/[slug]/content/[id].vue`):
  - Current version, sections, SEO plan display âœ…
  - Source info with ingest status âœ…
  - MDX body rendering âœ…
  - Editing chat module for in-context editing âœ…

**Testing Results** âœ…
- Natural conversation flow from chat to content generation
- Seamless integration between chat interface and staged pipeline
- Proper routing and navigation between chat and content detail views

---

## 6. Implementation Status Summary

### âœ… COMPLETED COMPONENTS

- **Database Schema**
  - `server/database/schema/chunk.ts` - Chunk table for transcript segments âœ…
  - `server/database/schema/index.ts` - Schema exports âœ…
  - Database migrations and schema synchronization âœ…

- **YouTube Ingest Pipeline**
  - `server/api/source-content/youtube.post.ts` - YouTube ingest endpoint âœ…
  - `server/services/sourceContent/chunkSourceContent.ts` - Chunking helper âœ…
  - `server/services/sourceContent/youtubeIngest.ts` - Modified for chunking âœ…
  - Google OAuth integration for YouTube captions âœ…

- **Content Generation Pipeline**
  - `server/services/content/generation.ts` - Rebuilt staged pipeline âœ…
    - Chunking/fetching stage (lines 62-215) âœ…
    - AI-planned brief stage (lines 300-406) âœ…
    - RAG-contextualized section generation (lines 409-640) âœ…
    - MDX assembly with metadata capture âœ…

- **UI Integration**
  - `app/pages/[slug]/chat.vue` - Real draft data in cards âœ…
  - `app/pages/[slug]/content/[id].vue` - Staged data display âœ…
  - Section-level UI with summaries and metadata âœ…
  - Navigation between chat and content detail views âœ…

- **API Endpoints**
  - `POST /api/source-content/youtube` âœ…
  - `POST /api/content/generate` (rebuilt with staged pipeline) âœ…
  - `POST /api/chat` (integrated with pipeline) âœ…

### âš ï¸ PARTIAL/MISSING COMPONENTS

- **SEO Analysis** - Basic metadata only, full analysis endpoint missing
- **Section Patching** - Foundation ready, dedicated endpoint not implemented
- **Dedicated Planning Endpoint** - Integrated into generation, not separate

### ğŸ¯ ACHIEVEMENT

**Successfully transformed monolithic content generation into a reusable, staged pipeline** that provides:
- End-to-end YouTube ingest with searchable chunks
- Deterministic plan â†’ sections â†’ assemble behavior  
- RAG-aware section generation with transcript context
- Section-first architecture with editing capabilities
- Chat-driven UX with natural conversation flow
- Real-time UI reflecting staged pipeline data

The implementation maintains backward compatibility while enabling the section-level editing and reusable pipeline architecture described in this plan.
